{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapchat Political Ads\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the reach (number of views) of an ad.\n",
    "    * Predict how much was spent on an ad.\n",
    "    * Predict the target group of an ad. (For example, predict the target gender.)\n",
    "    * Predict the (type of) organization/advertiser behind an ad.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "This project will focus on predicting the country of origin of the ad. This will be a classification problem since the goal is to predict a categorical variable, rather than continuous. In order to predict the country of origin, this project will use CountryCode as the target variable. The objective will be to maximize the accuracy of the model. Given the malicious ad campaigns that have taken place in the US by foreign governments, this project asks whether it is feasible to know where an ad originated from, with only knowing some basic information of the ad. For the purpose of addressing this question we will exclude billing address from the data as well.\n",
    "\n",
    "### Baseline Model\n",
    "For a baseline model I decided to first clean up my data a little. I first filled null values with their appropriate meanings based on snapchat's readme for the data. As well, I excluded columns that had over 95% null values as I do not think they would provide a better prediction. I ended up using 16 feature variables. Of the 16, 12 of the features were nominal, 2 features were quantitative, and 2 features were ordinal. As a baseline model, I decided to one hot encode all of the features except the two quantitative features, impressions and spend. I used a Random Forest Classifier and was able to achieve an average of approximately 63% after rerunning the model with different training and test data 50 times. For a baseline model, I feel this is a decent outcome since it is over 50% it shows that the data has the necessary relationships to be able to make a prediction of country origin.\n",
    "\n",
    "### Final Model\n",
    "TODO\n",
    "\n",
    "### Fairness Evaluation\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data \n",
    "ads_fp = os.path.join('data', 'PoliticalAds2018.csv')\n",
    "ads2018 = pd.read_csv(ads_fp)\n",
    "ads_fp = os.path.join('data', 'PoliticalAds2019.csv')\n",
    "ads2019 = pd.read_csv(ads_fp)\n",
    "ads = ads2018.append(ads2019)\n",
    "orig_ads = ads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with actual value the null is representing\n",
    "ads['Gender'] = ads['Gender'].fillna('ALL')\n",
    "ads['AgeBracket'] = ads['AgeBracket'].fillna('ALL')\n",
    "ads['Interests'] = ads['Interests'].fillna('NONE')\n",
    "ads['Language'] = ads['Language'].fillna('NONE')\n",
    "ads['CandidateBallotInformation'] = ads['CandidateBallotInformation'].fillna('NONE')\n",
    "ads['Regions (Included)'] = ads['Regions (Included)'].fillna('NONE')\n",
    "ads['Radius Targeting (Included)'] = ads['Radius Targeting (Included)'].fillna('NONE')\n",
    "ads['Postal Codes (Included)'] = ads['Postal Codes (Included)'].fillna('NONE')\n",
    "ads['EndDate'] = ads['EndDate'].fillna('ONGOING')\n",
    "ads['Segments'] = ads['Segments'].fillna('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that have over 95 % null values\n",
    "cols = ['Regions (Excluded)', 'Electoral Districts (Excluded)', 'Electoral Districts (Included)', \n",
    "       'Radius Targeting (Excluded)', 'Metros (Excluded)', 'Metros (Included)', \n",
    "       'Postal Codes (Excluded)', 'Location Categories (Excluded)', 'Location Categories (Included)', \n",
    "       'OsType', 'AdvancedDemographics', 'Targeting Connection Type', 'Targeting Carrier (ISP)', 'CreativeUrl',\n",
    "       'CreativeProperties']\n",
    "ads = ads.drop(cols, axis=1)\n",
    "# Drop ADID since it is a unique value for each ad\n",
    "ads = ads.drop(['ADID'], axis=1)\n",
    "# Dropping billing address since the point of the model is to predict origin location\n",
    "ads = ads.drop('BillingAddress', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing baseline features to use and creating a transformer to hold those features\n",
    "transformer = ColumnTransformer([\n",
    "    ('one_hot_curr', OneHotEncoder(), ['Currency Code']),\n",
    "    ('one_hot_start', OneHotEncoder(handle_unknown='ignore'), ['StartDate']),\n",
    "    ('one_hot_end', OneHotEncoder(handle_unknown='ignore'), ['EndDate']),\n",
    "    ('one_hot_org', OneHotEncoder(handle_unknown='ignore'), ['OrganizationName']),\n",
    "    ('one_hot_cand', OneHotEncoder(handle_unknown='ignore'), ['CandidateBallotInformation']),\n",
    "    ('one_hot_pay', OneHotEncoder(handle_unknown='ignore'), ['PayingAdvertiserName']),\n",
    "    ('one_hot_gender', OneHotEncoder(), ['Gender']),\n",
    "    ('one_hot_age', OneHotEncoder(handle_unknown='ignore'), ['AgeBracket']),\n",
    "    ('one_hot_regions', OneHotEncoder(handle_unknown='ignore'), ['Regions (Included)']),\n",
    "    ('one_hot_radius', OneHotEncoder(handle_unknown='ignore'), ['Radius Targeting (Included)']),\n",
    "    ('one_hot_postal', OneHotEncoder(handle_unknown='ignore'), ['Postal Codes (Included)']),\n",
    "    ('one_hot_int', OneHotEncoder(handle_unknown='ignore'), ['Interests']),\n",
    "    ('one_hot_seg', OneHotEncoder(handle_unknown='ignore'), ['Segments']),\n",
    "    ('one_hot_lan', OneHotEncoder(handle_unknown='ignore'), ['Language'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6349414519906323"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a pipeline to process transformations and execute random forest tree\n",
    "pl = Pipeline([\n",
    "        ('transformations', transformer),\n",
    "        ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "                min_samples_leaf=1, min_samples_split=2,\n",
    "                min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "                oob_score=False, random_state=None, verbose=0,\n",
    "                warm_start=False))\n",
    "])\n",
    "scores = []\n",
    "for i in range(50):\n",
    "    # Getting the X and y data along with training and testing data\n",
    "    X = ads.drop('CountryCode', axis=1)\n",
    "    y = ads['CountryCode']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    # Fitting the data\n",
    "    pl.fit(X_train, y_train)\n",
    "    # Getting the accuracy score\n",
    "    scores.append(accuracy_score(y_test, pl.predict(X_test)))\n",
    "np.mean(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
